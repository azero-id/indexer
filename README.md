# AZERO Domains â€“ Indexer (Subsquid)

This repository contains a [Subsquid](https://docs.subsquid.io/), indexing the smart contracts of AZERO Domains.

## Getting Started

```bash
# Install pnpm & @subsquid/cli
npm i -g pnpm @subsquid/cli

# Install dependencies
pnpm install

# Copy & fill environments
cp .env.example .env
```

## Development Quickstart

If needed, clear all existing docker images via `docker rm -f $(docker ps -a -q)`.

### Local Node

**Important:** Use [`aleph-node`](https://github.com/aleph-zero-foundation/aleph-node), `substrate-contracts-node` is not working currently due to its instant finality.

To index a locally running node, it's necessary to instantiate the following components in parallel:

- Subsquid Archive (only for local nodes)
- Subsquid Squid DB for Processor
- Subsquid Processor
- Subsquid GraphQL API

_All tasks need to be run in different terminal windows._

```bash
# Start Subsquid Archive (for local nodes only)
# NOTE: Does not work with `substrate-contracts-node` currently
pnpm run start:archive

# Start Squid DB (`sqd up`)
pnpm run start:squid

# Build & Start Processor (`sqd process`)
pnpm run codegen
pnpm run start:processor

# Serve Processor DB via GraphQL API (`sqd serve`)
pnpm run serve
```

### Live Node

To index a live network, no matter if it's a test or production network, no local archive must be started. Instead, the identifier for the matching remote archive has to be determined by running: `npx squid-archive-registry`. Then the `.env` file needs to be updated accordingly.

_All tasks need to be run in different terminal windows._

```bash
# Start Squid DB (`sqd up`)
pnpm run start:squid

# Build & Start Processor (`sqd process`)
pnpm run codegen
pnpm run start:processor

# Serve Processor DB via GraphQL API (`sqd serve`)
pnpm run serve
```

## Development Flow

### 1. Define database schema

Start development by defining the schema of the target database via `schema.graphql`.
Schema definition consists of regular graphql type declarations annotated with custom directives.
Full description of `schema.graphql` dialect is available [here](https://docs.subsquid.io/basics/schema-file).

### 2. Generate TypeORM classes

Mapping developers use TypeORM [EntityManager](https://typeorm.io/#/working-with-entity-manager)
to interact with target database during data processing. All necessary entity classes are
generated by the squid framework from `schema.graphql`. This is done by running `sqd codegen`
command.

### 3. Generate database migrations

All database changes are applied through migration files located at `db/migrations`.
`squid-typeorm-migration(1)` tool provides several commands to drive the process.

```bash
## drop create the database
sqd down
sqd up

## replace any old schemas with a new one made from the entities
sqd migration:generate
```

See [docs on database migrations](https://docs.subsquid.io/basics/db-migrations) for more details.

### 4. Import ABI contract and generate interfaces to decode events

It is necessary to import the respective ABI definition to decode WASM logs. For this template we used standard ERC20 interface, see [`abi/erc20.json`](abi/erc20.json).

To generate a type-safe facade class to decode EVM logs, use [`squid-ink-typegen(1)`](https://github.com/subsquid/squid-sdk/tree/master/substrate/ink-typegen):

```bash
npx squid-ink-typegen --abi abi/erc20.json --output src/abi/erc20.ts
```

## Project conventions

Squid tools assume a certain [project layout](https://docs.subsquid.io/basics/squid-structure):

- All compiled js files must reside in `lib` and all TypeScript sources in `src`.
  The layout of `lib` must reflect `src`.
- All TypeORM classes must be exported by `src/model/index.ts` (`lib/model` module).
- Database schema must be defined in `schema.graphql`.
- Database migrations must reside in `db/migrations` and must be plain js files.
- `sqd(1)` and `squid-*(1)` executables consult `.env` file for environment variables.
